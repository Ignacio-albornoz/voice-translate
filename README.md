# Traductor de Voz a Voz ğŸ™ï¸â‡‰ï¸ğŸ—£ï¸

Este proyecto convierte un archivo de voz en texto usando **Whisper** y **Pyannote**, traduce el texto a otro idioma y genera un nuevo archivo de audio.

### ğŸ”¥ TecnologÃ­as utilizadas
- [Whisper](https://github.com/openai/whisper) - TranscripciÃ³n automÃ¡tica
- [Pyannote.audio](https://github.com/pyannote/pyannote-audio) - DiarizaciÃ³n de hablantes
- [OpenAI API](https://platform.openai.com/) - TraducciÃ³n
- [Python](https://www.python.org/)
- [FFmpeg](https://ffmpeg.org/) - Procesamiento de audio

---

## ğŸš€ InstalaciÃ³n

1. **Clonar el repositorio**

```
git clone https://github.com/tu_usuario/tu_repositorio.git
cd tu_repositorio
```

2. **Crear entorno virtual**

```
python -m venv venv
```

3. **Activar entorno virtual**

- En Windows:

```
venv\Scripts\activate
```

- En Linux / Mac:

```
source venv/bin/activate
```

4. **Instalar dependencias**

```
pip install -r requirements.txt
```

5. **Configurar variables de entorno**

Crear un archivo `.env` en la raÃ­z del proyecto y agregar tus credenciales:

```
OPENAI_API_KEY=tu_clave_de_openai
HUGGINGFACE_TOKEN=tu_clave_de_huggingface
```

> âš ï¸ **Importante**: No compartas tu `.env` ni tus tokens.

6. **Instalar FFmpeg**

El proyecto requiere los binarios de **FFmpeg** para funcionar.

- Descargar FFmpeg desde [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)
- Extraer el contenido.
- Asegurarse que el ejecutable estÃ© disponible en el path `ffmpeg/bin` dentro del proyecto o que estÃ© agregado al **PATH del sistema**.

---

## ğŸ§ Uso

Ejecutar el proyecto pasando la ruta del audio de entrada:

```
python main.py --audio_path "ruta/del/audio.wav"
```

Por ejemplo:

```
python main.py --audio_path "audio_input/input2.wav"
```

Esto realiza de manera automÃ¡tica:

1. **DiarizaciÃ³n** (separaciÃ³n de hablantes).
2. **TranscripciÃ³n** (genera `output_transcript.txt`).
3. **TraducciÃ³n** y **generaciÃ³n de nuevas voces**.

---

## ğŸ“‚ Estructura del Proyecto

```
voice-translator/
â”œâ”€â”€ .env
â”œâ”€â”€ audio_input/
â”‚   â””â”€â”€ input2.wav
â”œâ”€â”€ output_transcript.txt
â”œâ”€â”€ diarization_transcription.py
â”œâ”€â”€ generate_voice.py
â”œâ”€â”€ main.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš¡ Notas adicionales
- **GPU recomendada** para mayor velocidad (Whisper y Pyannote son intensivos).
- FFmpeg debe estar instalado correctamente o el proyecto no podrÃ¡ procesar los audios.
- Actualmente el proyecto traduce y genera voces sobre un Ãºnico archivo de entrada por ejecuciÃ³n.

---

## ğŸ› ï¸ Futuras mejoras
- SelecciÃ³n de idioma de traducciÃ³n.
- Procesamiento por lotes de audios.
- GeneraciÃ³n de reportes de transcripciÃ³n y traducciÃ³n.

